# NLP models from scratch 

## Task 1: 
A minimal example to implement Transformers. 
![attention_shape](figs/attention_shape.jpeg)

## TODOs: 
- [] Bert from scratch 
- [] Fine-tuning 
- [] inspect neurons
- [] 

# References: 
  - [The Annotated Transformer](http://nlp.seas.harvard.edu/annotated-transformer/)
  - [The Annotated Transformer](https://github.com/gordicaleksa/pytorch-original-transformer/blob/main/The%20Annotated%20Transformer%20%2B%2B.ipynb)