# NLP models from scratch 

## Task 1: 
A minimal example to implement Transformers. 
![attention_shape](figs/attention_shape.jpeg)

## TODOs: 
- [] Bert from scratch 
- [] Fine-tuning 
- [] inspect neurons
- [] 

# References: 
  - [The Annotated Transformer](http://nlp.seas.harvard.edu/annotated-transformer/)